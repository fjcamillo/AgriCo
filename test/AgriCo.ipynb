{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgriCo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pylab as pl\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data  Preprocessing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SIZE = (28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rhino_url = \"/home/fjcamillo/Desktop/Hackzilla2/dataset/rhino/\"\n",
    "coconutmite_url = \"/home/fjcamillo/Desktop/Hackzilla2/dataset/coconutmite/\"\n",
    "lethalyellow_url = \"/home/fjcamillo/Desktop/Hackzilla2/dataset/lethalyellow/\"\n",
    "regular_url = \"/home/fjcamillo/Desktop/Hackzilla2/dataset/regular/\"\n",
    "stembleeding_url = \"/home/fjcamillo/Desktop/Hackzilla2/dataset/stembleeding/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "urls = [\n",
    "    rhino_url,\n",
    "    coconutmite_url,\n",
    "    lethalyellow_url,\n",
    "    regular_url,\n",
    "    stembleeding_url\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper function in creating new images\n",
    "\n",
    "#Populate Data Set\n",
    "def convert(filename, size, name, key, label):\n",
    "    img = Image.open(filename)\n",
    "    img = img.resize(size)\n",
    "    img.save(\"resized-{}-{}.png\".format(name, key))\n",
    "    rotate45 = img.rotate(45)\n",
    "    rotate45.save(\"rotate45-{}-{}.png\".format(name, key))\n",
    "    rotate90 = img.rotate(90)\n",
    "    rotate90.save(\"rotate90-{}-{}.png\".format(name, key))\n",
    "    bnw = img.convert(mode=\"L\")\n",
    "    bnw.save(\"bnw-{}-{}.png\".format(name, key))\n",
    "#     dit = img.convert(mode=\"P\")\n",
    "#     dit.save(\"dit-{}-{}.png\".format(name, key))\n",
    "    flip = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "    flip.save(\"flip-{}-{}.png\".format(name, key))\n",
    "#     return img\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Get links of images\n",
    "image_links = []\n",
    "for url in urls:\n",
    "    for dat in os.listdir(url):\n",
    "        image_links.append(url+dat)\n",
    "    \n",
    "image_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(image_links)*6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for image in image_links:\n",
    "    name = image.split(\"/\")[-2]\n",
    "    key = image.split(\"/\")[-1].split(\".\")[0]\n",
    "#     key = \"key\"\n",
    "    label = \"ok\"\n",
    "    convert(image, SIZE, name, key, label)\n",
    "    time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#helper function to create labels\n",
    "\n",
    "#rhino = 0\n",
    "#coconutmite = 1\n",
    "#lethalyellow = 2\n",
    "#stembleeding = 3\n",
    "#regular = 4\n",
    "\n",
    "def create_label(data):\n",
    "    if \"rhino\" in data: return [1,0,0,0,0]\n",
    "    if \"coconutmite\" in data: return [0,1,0,0,0]\n",
    "    if \"lethalyellow\" in data: return [0,0,1,0,0]\n",
    "    if \"stembleeding\" in data: return [0,0,0,1,0]\n",
    "    if \"regular\" in data: return [0,0,0,0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "final_dataset_link = \"/home/fjcamillo/Desktop/Hackzilla2/dataset/Final/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "proof = os.listdir(final_dataset_link)\n",
    "proof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = np.array([np.array(create_label(labe.split(\"-\"))) for labe in os.listdir(final_dataset_link)])\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#helper functions to create training set\n",
    "def convertimage(filename, verbose=False):\n",
    "    print(filename)\n",
    "    img = Image.open(filename)\n",
    "    print(np.array(img).shape)\n",
    "#     pl.imshow(img)\n",
    "#     img = img.resize(size)\n",
    "#     img = [list(img.getdata())]\n",
    "#     img = map(list, img)\n",
    "#     img = np.array(img)\n",
    "    return np.array(img).reshape((28,28,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#checker if image sizes\n",
    "def check(filename):\n",
    "    img = Image.open(filename)\n",
    "    sh = np.array(img).shape\n",
    "    if sh != (28,28,3):\n",
    "        print(\"filename: {}, shape: {}\".format(filename, sh))\n",
    "    else: pass\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Data Preprocessing: Checks the dimensions of the images\n",
    "for filen in os.listdir(final_dataset_link):\n",
    "    check(final_dataset_link+filen)\n",
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for filen in os.listdir(final_dataset_link):\n",
    "    fil = convertimage(final_dataset_link+filen)\n",
    "#     print(len(fil))\n",
    "    np.append(dataset, fil, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = np.array([convertimage(final_dataset_link+filen) for filen in os.listdir(final_dataset_link)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.save(\"agrico_training\", dataset, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Model (Image Classification)\n",
    "---\n",
    "\n",
    "A 5 convolutional neural network\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = np.array(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Linear Model\n",
    "linear_model = tf.matmul(x,W) + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = tf.reshape(x, [100, 512,512,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "512*512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_features = dataset[:536]\n",
    "training_labels = labels[:536]\n",
    "test_features = dataset[537:]\n",
    "test_labels = labels[537:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_features[:100].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_features[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_labels[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_labels[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Mini Batch Helper Function\n",
    "\n",
    "def next_batch(train_data, data_size):\n",
    "    pass\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with tf.device(\"/cpu:0\"):\n",
    "    x = tf.placeholder(tf.float32, [None,28,28,3]) #Shape = [how many, of size, of size, of channels]\n",
    "    y_ = tf.placeholder(tf.float32, [None, 5])\n",
    "    W = tf.Variable(tf.zeros([28,28]))\n",
    "    b = tf.Variable(tf.zeros([5]))\n",
    "    #Second Layer, First Convolution Input Layer\n",
    "    stddev = 1.0/math.sqrt(float(28*28))\n",
    "    W1 = tf.Variable(tf.truncated_normal([6,6,3,8], stddev=stddev))\n",
    "    b1 = tf.Variable(tf.zeros([8]))\n",
    "    #Third Layer, Second Convolution Input Layer\n",
    "    W2 = tf.Variable(tf.truncated_normal([5,5,8,12], stddev=stddev))\n",
    "    b2 = tf.Variable(tf.zeros([12]))\n",
    "    #Fourth Layer, Third Convolution Input Layer\n",
    "    W3 = tf.Variable(tf.truncated_normal([4,4,12,14], stddev=stddev))\n",
    "    b3 = tf.Variable(tf.zeros([14]))\n",
    "    #Fifth Layer, First Fully Connected Layer\n",
    "    W4 = tf.Variable(tf.truncated_normal([28*28*14,200], stddev=stddev))\n",
    "    b4 = tf.Variable(tf.zeros([200]))\n",
    "    #Fifth Layer, First Fully Connected Layer\n",
    "    W5 = tf.Variable(tf.truncated_normal([200,5], stddev=stddev))\n",
    "    b5 = tf.Variable(tf.zeros([5]))\n",
    "    #Model\n",
    "    conv1 = tf.nn.relu(tf.nn.conv2d(x, W1, strides=[1,1,1,1], padding=\"SAME\") + b1)\n",
    "    conv2 = tf.nn.relu(tf.nn.conv2d(conv1, W2, strides=[1,1,1,1], padding=\"SAME\")+b2)\n",
    "    conv3 = tf.nn.relu(tf.nn.conv2d(conv2, W3, strides=[1,1,1,1], padding=\"SAME\")+b3)\n",
    "    \n",
    "    \n",
    "    reenter = tf.reshape(conv3, [-1,28*28*14])\n",
    "    \n",
    "    \n",
    "    fc1 = tf.nn.relu(tf.matmul(reenter,W4) + b4)\n",
    "    fc2 = tf.matmul(fc1, W5) + b5\n",
    "    Y = tf.nn.softmax_cross_entropy_with_logits(labels=y_,logits=fc2)\n",
    "    loss = tf.reduce_mean(Y) + 5\n",
    "    \n",
    "    #\n",
    "#     print(fc2)\n",
    "    \n",
    "    #loss function \n",
    "    train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "    \n",
    "    #accuracy\n",
    "#     print(\"loss: {}, y_: {}\".format(loss, y_))\n",
    "    correct_prediction = tf.equal(tf.argmax(y_,1),tf.argmax(Y,-1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    #Debugger\n",
    "    print(\"Conv1:\\t\\t{}\".format(conv1.get_shape()))\n",
    "    print(\"Conv2:\\t\\t{}\".format(conv2.get_shape()))\n",
    "    print(\"Conv3:\\t\\t{}\".format(conv3.get_shape()))\n",
    "    print(\"fc1:\\t\\t{}\".format(fc1.get_shape()))\n",
    "    print(\"fc2:\\t\\t{}\".format(fc2.get_shape()))\n",
    "    print(\"Corr:\\t\\t{}\".format(correct_prediction.get_shape()))\n",
    "    print(\"Accur:\\t\\t{}\".format(accuracy.get_shape()))\n",
    "    print(\"loss:\\t\\t{}\".format(loss.get_shape()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train\n",
    "for i in range(2000):\n",
    "#     batch = mnist.train.next_batch(50)\n",
    "#     print(i)\n",
    "    if i%100==0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x:training_features[:600],y_:training_labels[:600]})\n",
    "        print(\"Step {}, training accuracy {}\".format(i, train_accuracy))\n",
    "    train_step.run(feed_dict={x:training_features[:600],y_:training_labels[:600]})\n",
    "\n",
    "print(\"test accuracy {}\".format(accuracy.eval(feed_dict={x:test_features[:], y_:test_labels[:]})))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Model (Hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rhino_data = [[np.random.randint(1, 200), np.random.randint(1, 200),np.random.randint(1, 200),np.random.randint(1, 200),np.random.randint(1, 200),np.random.randint(1, 200)] for i in range(500)]\n",
    "rhino_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "yellow_data=[[np.random.randint(201, 400), np.random.randint(201, 400),np.random.randint(201, 400),np.random.randint(201, 400),np.random.randint(201, 400),np.random.randint(201, 400)] for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stem_data=[[np.random.randint(301, 600), np.random.randint(301, 600),np.random.randint(301, 600),np.random.randint(301, 600),np.random.randint(301, 600),np.random.randint(301, 600)] for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "regular_data=[[np.random.randint(401, 700), np.random.randint(401, 700),np.random.randint(401, 700),np.random.randint(401, 700),np.random.randint(401, 700),np.random.randint(401, 700)] for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coconutmite_data=[[np.random.randint(500, 800), np.random.randint(500, 800),np.random.randint(500, 800),np.random.randint(500, 800),np.random.randint(500, 800),np.random.randint(500, 800)] for i in range(500)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_data=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hard_data.append([np.random.randint(201, 400), np.random.randint(201, 400),np.random.randint(201, 400),np.random.randint(201, 400),np.random.randint(201, 400),np.random.randint(201, 400)] for i in range(500))\n",
    "hard_data.append([np.random.randint(301, 600), np.random.randint(301, 600),np.random.randint(301, 600),np.random.randint(301, 600),np.random.randint(301, 600),np.random.randint(301, 600)] for i in range(500))\n",
    "hard_data.append([np.random.randint(1, 200), np.random.randint(1, 200),np.random.randint(1, 200),np.random.randint(1, 200),np.random.randint(1, 200),np.random.randint(1, 200)] for i in range(500))\n",
    "hard_data.append([np.random.randint(401, 700), np.random.randint(401, 700),np.random.randint(401, 700),np.random.randint(401, 700),np.random.randint(401, 700),np.random.randint(401, 700)] for i in range(500))\n",
    "hard_data.append([np.random.randint(500, 800), np.random.randint(500, 800),np.random.randint(500, 800),np.random.randint(500, 800),np.random.randint(500, 800),np.random.randint(500, 800)] for i in range(500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for rhi in rhino_data:\n",
    "    hard_data.append(rhi)\n",
    "\n",
    "for rhi in yellow_data:\n",
    "    hard_data.append(rhi)\n",
    "    \n",
    "for rhi in regular_data:\n",
    "    hard_data.append(rhi)\n",
    "\n",
    "for rhi in stem_data:\n",
    "    hard_data.append(rhi)\n",
    "\n",
    "for rhi in coconutmite_data:\n",
    "    hard_data.append(rhi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_data.append(rhi for rhi in rhino_data)\n",
    "hard_data.append(rhi for rhi in yellow_data)\n",
    "hard_data.append(rhi for rhi in regular_data)\n",
    "hard_data.append(rhi for rhi in stem_data)\n",
    "hard_data.append(rhi for rhi in coconutmite_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# hard_data = [[np.random.randint(30), np.random.randint(990),np.random.randint(990),np.random.randint(990),np.random.randint(990), np.random.randint(990)] for i in range(500)]\n",
    "# hard_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(hard_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_labels = [\"coconut mite\", \"rhinocerus insect\", \"lethal yellowing\", \"stem bleeding\", \"regular\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def adjusthard(da):\n",
    "    if da<500: return 0\n",
    "    if da>500 and da<1000: return 1\n",
    "    if da>500 and da<1000 and da<1500: return 0\n",
    "    if da>500 and da<1000: return 0\n",
    "    if da>500 and da<1000: return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for x in range(1):\n",
    "    for i in range(500):\n",
    "        hard_actual_labels.append(0)\n",
    "    for i in range(500):\n",
    "        hard_actual_labels.append(1)\n",
    "    for i in range(500):\n",
    "        hard_actual_labels.append(2)\n",
    "    for i in range(500):\n",
    "        hard_actual_labels.append(3)\n",
    "    for i in range(500):\n",
    "        hard_actual_labels.append(4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_actual_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.array(hard_actual_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_data = [\n",
    "#   [Temperature, Distance, Light]\n",
    "#   [25-30, 900-990, 750-990]\n",
    "    [25, 70, 1500],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_hard = hard_data[:]\n",
    "training_label = hard_actual_labels[:400]\n",
    "test_hard = hard_data[401:]\n",
    "test_label=hard_actual_labels[401:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertforsklearn(dat):\n",
    "    if dat[0] == 1: return int(0)\n",
    "    if dat[1] == 1: return int(1)\n",
    "    if dat[2] == 1: return int(2)\n",
    "    if dat[3] == 1: return int(3)\n",
    "    if dat[4] == 1: return int(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "converted_hard = [convertforsklearn(datr) for datr in hard_actual_labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "getThis = [np.random.randint(0, 2500) for _ in range(2000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "training_hard = [hard_data[da] for da in getThis]\n",
    "test_hard = [hard_data[da]  for da in range(2500) if da not in getThis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "converted_train = hard_actual_labels[:2000]\n",
    "converted_test = hard_actual_labels[1378:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#[400,1,6], [6,200,1]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostRegressor\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier().fit(training_hard,converted_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = clf.predict(test_hard)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard_score=1-hard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hard_score = accuracy_score(converted_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hard_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Input Layer\n",
    "x = tf.placeholder(tf.float32, [400*6,5])\n",
    "# y_ = tf.placeholder(tf.float32, [None,6])\n",
    "W = tf.Variable(tf.zeros([400*6,5]))\n",
    "b = tf.Variable(tf.zeros([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Second Layer\n",
    "W2 = tf.Variable(tf.truncated_normal([400,100],stddev=0.1) )\n",
    "b2 = tf.Variable(tf.ones([100]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Third Layer\n",
    "W3 = tf.Variable(tf.truncated_normal([100,50],stddev=0.1) )\n",
    "b3 = tf.Variable(tf.ones([50]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fourth Layer\n",
    "W4 = tf.Variable(tf.truncated_normal([50,25],stddev=0.1))\n",
    "b4 = tf.Variable(tf.ones([25]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fifth Layer\n",
    "W5 = tf.Variable(tf.truncated_normal([25,5], stddev=0.1))\n",
    "b5 = tf.Variable(tf.ones([5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Model\n",
    "fc1 = tf.nn.relu(tf.matmul(x, W) + b)\n",
    "fc2 = tf.nn.relu(tf.matmul(fc1, W2) + b2)\n",
    "fc3 = tf.nn.relu(tf.matmul(fc2, W3) + b3)\n",
    "fc4 = tf.nn.relu(tf.matmul(fc3, W4) + b4)\n",
    "fc5 = tf.nn.softmax(tf.matmul(fc4, W5) + b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_step = tf.train.GradientDescentOptimizer(fc5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
